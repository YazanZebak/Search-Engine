# Search-Engine
Information Retrieval System (Search Engine) that utilizes TF-IDF and Word2Vec models, as well as cosine similarity, to match and rank queries against a collection of documents. The search engine supports multiple preprocessing techniques for English, Arabic and French datasets, providing accurate and relevant search results.

# Datasets

<a href="https://ir-datasets.com/wikir.html#wikir/en1k"> WikIR for English. </a>

<a href="https://ir-datasets.com/wikir.html#wikir/fr14k"> WikIR for French. </a>

<a href="https://ir-datasets.com/mr-tydi.html#mr-tydi/ar"> Mr. TyDi for Arabic. </a>

# Project Features

<b> Preprocessing: </b> The project incorporates several preprocessing techniques such as tokenization, stemming, lemmatization, and spell checking to enhance the quality of text data.

<b> Inverted Index: </b> The project utilizes an inverted index data structure to efficiently store and retrieve information about the occurrences of words in the documents. This allows for faster searching and retrieval of relevant documents.

<b> TF-IDF Model: </b> The TF-IDF model is used to compute the importance of words in documents and queries, enabling efficient retrieval of relevant information.

<b> Word2Vec Model: </b> The Word2Vec model generates word embeddings that capture the semantic meaning of words, improving the understanding and accuracy of search results.

<b> Cosine Similarity: </b> Cosine similarity is employed to measure the similarity between queries and documents, facilitating effective matching and ranking.

<b> Evaluation of Search Results: </b> The project implement methods to evaluate and rank the search results based on their relevance to the query, using techniques such as precision at k (P@k), recall, mean reciprocal rank (MRR) and mean average precision (MAP).

<b> API with Flask: </b> The search engine is deployed as a Flask-based API that offers various endpoints to interact with the system. 

# Project Structure
- datasets/
  - [Dataset files]
- engine/
  - core/
    - models/
    - preprocess/
    - spell_checker/
  - evaluation/
  - utils/
- output/
- server.py

<b>datasets:</b> This directory contains the datasets used in the project.

<b>engine:</b> This directory contains the main engine of the project.

<b>core:</b> This subdirectory contains the core functionality of the engine.

<b>models:</b> This subdirectory contains the models used in the project.

<b>preprocess:</b> This subdirectory contains the preprocessing functionality.

<b>spell_checker:</b> This subdirectory contains the spell checker functionality.

<b>evaluation:</b> This subdirectory contains evaluation scripts and metrics.

<b>utils:</b> This subdirectory contains utility functions and helper modules.

<b>output:</b> This directory is used to store the output files generated by the project.

<b>server.py:</b> This file contains the Flask server code for running the project's services.

# Services

    Choose Dataset: This service allows you to choose a dataset for processing. It expects a JSON payload with the dataset parameter specifying the dataset name.
    Endpoint: /choose-dataset
    Method: POST
    Payload: { "dataset": "dataset_name" }
    
    Correct: This service performs spell checking on a given query. It expects a JSON payload with the query parameter specifying the input query.
    Endpoint: /correct
    Method: POST
    Payload: { "query": "input_query" }
    
    Search: This service performs a search operation on a given query. It expects a JSON payload with the query parameter specifying the search query.
    Endpoint: /search
    Method: POST
    Payload: { "query": "search_query" }

